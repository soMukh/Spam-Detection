{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46d5207f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\etern\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Label</th>\n",
       "      <th>Message</th>\n",
       "      <th>label_num</th>\n",
       "      <th>message</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>605.0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\nth...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2349.0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\n( see a...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3624.0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\nho ho ho , we ' re arou...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4685.0</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030.0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs\\nthis deal is to ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Label                                            Message  \\\n",
       "0       605.0   ham  Subject: enron methanol ; meter # : 988291\\nth...   \n",
       "1      2349.0   ham  Subject: hpl nom for january 9 , 2001\\n( see a...   \n",
       "2      3624.0   ham  Subject: neon retreat\\nho ho ho , we ' re arou...   \n",
       "3      4685.0  spam  Subject: photoshop , windows , office . cheap ...   \n",
       "4      2030.0   ham  Subject: re : indian springs\\nthis deal is to ...   \n",
       "\n",
       "   label_num message class  \n",
       "0        0.0     NaN   NaN  \n",
       "1        0.0     NaN   NaN  \n",
       "2        0.0     NaN   NaN  \n",
       "3        1.0     NaN   NaN  \n",
       "4        0.0     NaN   NaN  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "data = pd.read_csv(\"spamham.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bcdaba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "corpus = []\n",
    "\n",
    "# Optional: Drop rows with missing values in 'Message'\n",
    "data = data.dropna(subset=['Message'])\n",
    "\n",
    "# Make sure all values are strings\n",
    "data['Message'] = data['Message'].astype(str)\n",
    "\n",
    "for i in range(0, len(data)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', data['Message'][i])  # Remove non-letters\n",
    "    review = review.lower()                                # Lowercase\n",
    "    review = review.split()                                # Tokenize\n",
    "    \n",
    "    # Remove stopwords and apply stemming\n",
    "    review = [ps.stem(word) for word in review if word not in stopwords.words('english')]\n",
    "    review = ' '.join(review)                              # Re-join words\n",
    "    corpus.append(review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36df6a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "x = cv.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a6a43a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81560ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Label'].map({'ham':0, 'spam':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cc85bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       1\n",
       "4       0\n",
       "       ..\n",
       "5166    0\n",
       "5167    0\n",
       "5168    0\n",
       "5169    0\n",
       "5170    1\n",
       "Name: Label, Length: 5171, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaeba00",
   "metadata": {},
   "source": [
    "## Grid Search\n",
    "\n",
    "- Why do we use Grid Search?\n",
    "\n",
    "`GridSearchCV` is a technique to search through the best parameter values from the given set of the grid of parameters. It is basically a cross-validation method. the model and the parameters are required to be fed in. Best parameter values are extracted and then the predictions are made."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85158b53",
   "metadata": {},
   "source": [
    "## Select the best model\n",
    "- so here we have some list of the best text classification algorithms we imported. Now we will compare each model's score and see which model is performing better than rest of the others"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a928453",
   "metadata": {},
   "source": [
    "### 1. Multinomial Naive Bayes Classifier\n",
    "\n",
    "The multinomial NB classifier has a hyperparameter called **`alpha`**. It is the **smoothing parameter** to avoid **zero counts** when calculating the frequencies. \n",
    "\n",
    "For example, if we are now classifying a new SMS with a word \"ryan\" which never exist in the spam emails within our training dataset, the **likelihood** for this word will be zero. This will casue the **overall likelihood** to be zero (because we take the product of all **individual likelihoods**) for no matter what class of output variable we have.\n",
    "\n",
    "Therefore, we need to add **additional counts** to each word when calculating the frequencies to avoid have a zero likelihood value. **Alpha** indicates how many **additional counts** we add."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2739d885",
   "metadata": {},
   "source": [
    "### 2. Gaussian Naive Bayes Classifier\n",
    "\n",
    "There is one hyperparameter we need to tune: **`var_smoothing`**. This is the **portion of the largest variance** of all features that is added to variances for **calculation stability**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a83390",
   "metadata": {},
   "source": [
    "### 3. SVC\n",
    "SVC, or Support Vector Classifier, is a supervised machine learning algorithm typically used for classification tasks. SVC works by mapping data points to a high-dimensional space and then finding the optimal hyperplane that divides the data into two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28911581",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "models = {\n",
    "    \"Multinomial Naive Bayes\": MultinomialNB(),\n",
    "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "    \"SVC\": SVC()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9802e9",
   "metadata": {},
   "source": [
    "- ### We will create a generic function to check each model's performance so that we can compare those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e3250ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function which can evaluate models and return a report \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "def evaluate_models(X, y, models):\n",
    "    '''\n",
    "    This function takes in X and y and models dictionary as input\n",
    "    It splits the data into Train Test split\n",
    "    Iterates through the given model dictionary and evaluates the metrics\n",
    "    Returns: Dataframe which contains report of all models metrics with cost\n",
    "    '''\n",
    "    # separate dataset into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "    \n",
    "\n",
    "    models_list = []\n",
    "    scores = []\n",
    "    \n",
    "    for i in range(len(list(models))):\n",
    "        model = list(models.values())[i]\n",
    "        model.fit(X_train, y_train) # Train model\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        score = accuracy_score(y_test,y_pred)\n",
    "        \n",
    "        model_name = list(models.keys())[i]\n",
    "        print(f'---- score for --- {model_name} ----')\n",
    "        print(f\"{score}\")\n",
    "        models_list.append(model_name)\n",
    "        scores.append(score)\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    report = pd.DataFrame()\n",
    "    report['Model_name'] = models_list\n",
    "    report['Score'] = scores        \n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5d0768f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- score for --- Multinomial Naive Bayes ----\n",
      "0.9777777777777777\n",
      "---- score for --- Gaussian Naive Bayes ----\n",
      "0.9526570048309179\n",
      "---- score for --- SVC ----\n",
      "0.9594202898550724\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = evaluate_models(x, y, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "441c6427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_name</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>0.952657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.959420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>0.977778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model_name     Score\n",
       "1     Gaussian Naive Bayes  0.952657\n",
       "2                      SVC  0.959420\n",
       "0  Multinomial Naive Bayes  0.977778"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report.sort_values('Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b914f889",
   "metadata": {},
   "source": [
    "- ### From the report above we can see that the Multinomial Naive Bayes model performed the best, so we will continue training our model using Multinomial Naive Bayes algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23b0db71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2686f15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'alpha': 0.1}\n",
      "accuracy : 0.9779971259835621\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy as np\n",
    "\n",
    "params = {\n",
    "    'alpha': np.linspace(0.1, 1.0, 10)  \n",
    "}\n",
    "mnb_model = MultinomialNB()\n",
    "mnb_cv = GridSearchCV(mnb_model, params, cv = 5)\n",
    "mnb_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"tuned hpyerparameters :(best parameters) \",mnb_cv.best_params_)\n",
    "print(\"accuracy :\",mnb_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd35d11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 0.9768115942028985\n",
      "The confusion matrix is: \n",
      "[[728  14]\n",
      " [ 10 283]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "spam_detect_model = MultinomialNB(**mnb_cv.best_params_)\n",
    "spam_detect_model.fit(X_train, y_train)\n",
    "y_pred = spam_detect_model.predict(X_test)\n",
    "confusion_m = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy of the model is {accuracy}\")\n",
    "print(f\"The confusion matrix is: \\n{confusion_m}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb12489e",
   "metadata": {},
   "source": [
    "- So we can see that the model performed well and we have got an accuracy of 96% which is pretty insane. In our project we will be having all these models and we will be selecting the models based on the performence."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
